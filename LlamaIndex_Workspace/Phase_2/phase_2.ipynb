{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings, SimpleDirectoryReader\n",
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../data\").load_data()\n",
    "llm = Ollama(model=\"llama3\", request_timeout=120.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enes227\\environments\\llama_environment\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f19be6c67f410ab914154fe26cb1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54897bbd830a47b4827504213cb08bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(documents,embed_model=Settings.embed_model,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it can be inferred that the author works multiple jobs or pursues various ventures to make a living. Initially, he is a student at the Accademia and later returns to RISD, but ultimately decides to get a job at Interleaf to fund his studies. After completing his education, he begins working on software for creating documents, which leads him to learn about low-end software eating high-end software. He also works on spam filters, paints still lives, and buys an office building in Cambridge. Additionally, he starts publishing essays online and becomes involved with startups, which ultimately leads him to meet Jessica Livingston and collaborate on a book of interviews with startup founders.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine(llm=llm)\n",
    "response = query_engine.query(\n",
    "    \"What does the author do to live?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "evaluator = FaithfulnessEvaluator(llm=llm)\n",
    "eval_result = evaluator.evaluate_response(response=response)\n",
    "print(str(eval_result.passing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import MockLLM\n",
    "from llama_index.core import MockEmbedding\n",
    "\n",
    "llm = MockLLM(max_tokens=256)\n",
    "embed_model = MockEmbedding(embed_dim=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "agent = ReActAgent.from_tools([multiply_tool], llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I can use a tool to help me calculate the multiplication result.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2123, 'b': 215123}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 456706129\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The result of multiplying 2123 and 215123 is indeed 456706129.\n",
      "Answer: 456706129\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='456706129', sources=[ToolOutput(content='456706129', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 2123, 'b': 215123}}, raw_output=456706129, is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"What is 2123 * 215123\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
